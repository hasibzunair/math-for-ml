{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit MLP to dataset and print error\n",
    "def fit_model(X, y):\n",
    "    \n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    # fit network\n",
    "    model.fit(X, y, epochs=100, batch_size=len(X), verbose=0)\n",
    "    \n",
    "    # forecast\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    loss = mean_squared_error(y, yhat[:,0])\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99,), (99,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sequence\n",
    "length = 100\n",
    "sequence = [i/float(length) for i in range(length)]\n",
    "# create X/y pairs\n",
    "df = DataFrame(sequence)\n",
    "df = concat([df.shift(1), df], axis=1)\n",
    "df.dropna(inplace=True)\n",
    "# convert to MLP friendly format\n",
    "values = df.values\n",
    "X, y = values[:,0], values[:,1]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20504675932589295\n",
      "0.0035844285690576874\n",
      "0.03778201311249263\n",
      "0.005331703756795706\n",
      "3.98544413026156e-06\n",
      "0.028832257424588736\n",
      "0.08043158979278815\n",
      "0.0020255502861990364\n",
      "0.002352213185761803\n",
      "0.006751705834386256\n",
      "0.0038943752735889616\n",
      "0.001324593520886964\n",
      "0.1885007621293925\n",
      "1.718670880108647e-07\n",
      "0.2431189295010302\n",
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "# repeat experiment\n",
    "repeats = 15\n",
    "\n",
    "vals = []\n",
    "for _ in range(repeats):\n",
    "    loss = fit_model(X, y)\n",
    "    vals.append(loss)\n",
    "    \n",
    "vals = np.array(vals)\n",
    "print(vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01546660582754107 0.015497887491323659\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(vals)\n",
    "std = np.std(vals)\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MLP with manual validation set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s 575us/step - loss: 4.6352 - accuracy: 0.5798 - val_loss: 1.3942 - val_accuracy: 0.5157\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 1.2285 - accuracy: 0.5467 - val_loss: 0.9711 - val_accuracy: 0.5748\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.8792 - accuracy: 0.6070 - val_loss: 0.8189 - val_accuracy: 0.6024\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.8062 - accuracy: 0.5914 - val_loss: 0.7494 - val_accuracy: 0.6260\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.7094 - accuracy: 0.6576 - val_loss: 0.7278 - val_accuracy: 0.6378\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.7241 - accuracy: 0.6265 - val_loss: 0.7183 - val_accuracy: 0.6496\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.6911 - accuracy: 0.6634 - val_loss: 0.7030 - val_accuracy: 0.6850\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.6881 - accuracy: 0.6537 - val_loss: 0.7845 - val_accuracy: 0.5748\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s 177us/step - loss: 0.6863 - accuracy: 0.6634 - val_loss: 0.7022 - val_accuracy: 0.6614\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.6762 - accuracy: 0.6829 - val_loss: 0.7681 - val_accuracy: 0.6811\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.6701 - accuracy: 0.6809 - val_loss: 0.6730 - val_accuracy: 0.6890\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.6565 - accuracy: 0.6693 - val_loss: 0.6542 - val_accuracy: 0.6811\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.6582 - accuracy: 0.6732 - val_loss: 0.6912 - val_accuracy: 0.6417\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.6273 - accuracy: 0.6868 - val_loss: 0.6694 - val_accuracy: 0.6969\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.6240 - accuracy: 0.6868 - val_loss: 0.6553 - val_accuracy: 0.6772\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.6296 - accuracy: 0.6887 - val_loss: 0.6448 - val_accuracy: 0.6654\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.6212 - accuracy: 0.6907 - val_loss: 0.6621 - val_accuracy: 0.6654\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.6224 - accuracy: 0.6926 - val_loss: 0.7061 - val_accuracy: 0.6299\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.6139 - accuracy: 0.6926 - val_loss: 0.6311 - val_accuracy: 0.6929\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s 177us/step - loss: 0.6108 - accuracy: 0.6829 - val_loss: 0.6505 - val_accuracy: 0.6811\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.6097 - accuracy: 0.7043 - val_loss: 0.6246 - val_accuracy: 0.6772\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5867 - accuracy: 0.7121 - val_loss: 0.6144 - val_accuracy: 0.6850\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.6075 - accuracy: 0.7140 - val_loss: 0.6233 - val_accuracy: 0.6890\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.5924 - accuracy: 0.7062 - val_loss: 0.6198 - val_accuracy: 0.6850\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s 193us/step - loss: 0.5947 - accuracy: 0.7004 - val_loss: 0.6324 - val_accuracy: 0.6890\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.6258 - accuracy: 0.6809 - val_loss: 0.6424 - val_accuracy: 0.6535\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.5872 - accuracy: 0.7043 - val_loss: 0.6505 - val_accuracy: 0.6772\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s 177us/step - loss: 0.5702 - accuracy: 0.7160 - val_loss: 0.6137 - val_accuracy: 0.6811\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5823 - accuracy: 0.7179 - val_loss: 0.6081 - val_accuracy: 0.6850\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.6020 - accuracy: 0.6868 - val_loss: 0.6221 - val_accuracy: 0.6850\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5830 - accuracy: 0.7179 - val_loss: 0.5955 - val_accuracy: 0.7047\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5819 - accuracy: 0.7004 - val_loss: 0.6080 - val_accuracy: 0.7126\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.5611 - accuracy: 0.7237 - val_loss: 0.6051 - val_accuracy: 0.7047\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s 203us/step - loss: 0.5593 - accuracy: 0.7257 - val_loss: 0.5965 - val_accuracy: 0.6929\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s 198us/step - loss: 0.5766 - accuracy: 0.6829 - val_loss: 0.5927 - val_accuracy: 0.7087\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.5571 - accuracy: 0.7121 - val_loss: 0.6094 - val_accuracy: 0.6535\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s 190us/step - loss: 0.5492 - accuracy: 0.7315 - val_loss: 0.5861 - val_accuracy: 0.7087\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5588 - accuracy: 0.7276 - val_loss: 0.5995 - val_accuracy: 0.7047\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s 194us/step - loss: 0.5678 - accuracy: 0.7082 - val_loss: 0.6181 - val_accuracy: 0.6811\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5623 - accuracy: 0.7179 - val_loss: 0.5748 - val_accuracy: 0.7205\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.5441 - accuracy: 0.7315 - val_loss: 0.5932 - val_accuracy: 0.7087\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s 192us/step - loss: 0.5485 - accuracy: 0.7082 - val_loss: 0.5972 - val_accuracy: 0.7047\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.5433 - accuracy: 0.7412 - val_loss: 0.5711 - val_accuracy: 0.7323\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.5459 - accuracy: 0.7218 - val_loss: 0.5666 - val_accuracy: 0.7362\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.5598 - accuracy: 0.7140 - val_loss: 0.5996 - val_accuracy: 0.7165\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5616 - accuracy: 0.7140 - val_loss: 0.6173 - val_accuracy: 0.6850\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.5506 - accuracy: 0.7101 - val_loss: 0.5727 - val_accuracy: 0.7087\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.5350 - accuracy: 0.7237 - val_loss: 0.5863 - val_accuracy: 0.7008\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s 198us/step - loss: 0.5417 - accuracy: 0.7296 - val_loss: 0.5679 - val_accuracy: 0.7362\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.5321 - accuracy: 0.7471 - val_loss: 0.5646 - val_accuracy: 0.7323\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.5364 - accuracy: 0.7665 - val_loss: 0.5742 - val_accuracy: 0.7244\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.5301 - accuracy: 0.7471 - val_loss: 0.5792 - val_accuracy: 0.7126\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s 192us/step - loss: 0.5414 - accuracy: 0.7354 - val_loss: 0.5764 - val_accuracy: 0.7362\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s 193us/step - loss: 0.5604 - accuracy: 0.7257 - val_loss: 0.5777 - val_accuracy: 0.6929\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5504 - accuracy: 0.7179 - val_loss: 0.5728 - val_accuracy: 0.7126\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s 196us/step - loss: 0.5545 - accuracy: 0.7198 - val_loss: 0.5930 - val_accuracy: 0.6929\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s 196us/step - loss: 0.5752 - accuracy: 0.7121 - val_loss: 0.5757 - val_accuracy: 0.7205\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s 190us/step - loss: 0.5407 - accuracy: 0.7296 - val_loss: 0.5549 - val_accuracy: 0.7362\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.5248 - accuracy: 0.7510 - val_loss: 0.5860 - val_accuracy: 0.7205\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5359 - accuracy: 0.7471 - val_loss: 0.5736 - val_accuracy: 0.7244\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5315 - accuracy: 0.7315 - val_loss: 0.5632 - val_accuracy: 0.7441\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.5206 - accuracy: 0.7451 - val_loss: 0.5735 - val_accuracy: 0.7087\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5337 - accuracy: 0.7276 - val_loss: 0.6072 - val_accuracy: 0.7047\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.5407 - accuracy: 0.7296 - val_loss: 0.6237 - val_accuracy: 0.6850\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s 170us/step - loss: 0.5320 - accuracy: 0.7335 - val_loss: 0.5646 - val_accuracy: 0.7480\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5578 - accuracy: 0.7393 - val_loss: 0.6081 - val_accuracy: 0.6969\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.5240 - accuracy: 0.7374 - val_loss: 0.5562 - val_accuracy: 0.7205\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5286 - accuracy: 0.7315 - val_loss: 0.5698 - val_accuracy: 0.7598\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.5154 - accuracy: 0.7432 - val_loss: 0.5805 - val_accuracy: 0.7165\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s 194us/step - loss: 0.5264 - accuracy: 0.7218 - val_loss: 0.5659 - val_accuracy: 0.7244\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.5136 - accuracy: 0.7393 - val_loss: 0.5598 - val_accuracy: 0.7441\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.5489 - accuracy: 0.7296 - val_loss: 0.5644 - val_accuracy: 0.7520\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s 221us/step - loss: 0.5128 - accuracy: 0.7335 - val_loss: 0.6017 - val_accuracy: 0.6890\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s 198us/step - loss: 0.5426 - accuracy: 0.7296 - val_loss: 0.5636 - val_accuracy: 0.7441\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5442 - accuracy: 0.7237 - val_loss: 0.6034 - val_accuracy: 0.6929\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s 172us/step - loss: 0.5304 - accuracy: 0.7315 - val_loss: 0.5938 - val_accuracy: 0.6969\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s 171us/step - loss: 0.5199 - accuracy: 0.7432 - val_loss: 0.5790 - val_accuracy: 0.7480\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.5098 - accuracy: 0.7490 - val_loss: 0.5768 - val_accuracy: 0.7402\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s 203us/step - loss: 0.5266 - accuracy: 0.7412 - val_loss: 0.5678 - val_accuracy: 0.7520\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5237 - accuracy: 0.7354 - val_loss: 0.5585 - val_accuracy: 0.7441\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s 170us/step - loss: 0.5151 - accuracy: 0.7432 - val_loss: 0.5649 - val_accuracy: 0.7441\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.5392 - accuracy: 0.7296 - val_loss: 0.5675 - val_accuracy: 0.7559\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5193 - accuracy: 0.7588 - val_loss: 0.7124 - val_accuracy: 0.6575\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.5082 - accuracy: 0.7588 - val_loss: 0.5628 - val_accuracy: 0.7165\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.5302 - accuracy: 0.7471 - val_loss: 0.5808 - val_accuracy: 0.7244\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s 201us/step - loss: 0.5255 - accuracy: 0.7471 - val_loss: 0.5679 - val_accuracy: 0.6850\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.5235 - accuracy: 0.7296 - val_loss: 0.5663 - val_accuracy: 0.7441\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s 192us/step - loss: 0.5169 - accuracy: 0.7529 - val_loss: 0.5743 - val_accuracy: 0.7047\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.5151 - accuracy: 0.7510 - val_loss: 0.5687 - val_accuracy: 0.7677\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.5192 - accuracy: 0.7237 - val_loss: 0.6388 - val_accuracy: 0.6693\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5153 - accuracy: 0.7549 - val_loss: 0.5612 - val_accuracy: 0.7047\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5168 - accuracy: 0.7335 - val_loss: 0.5556 - val_accuracy: 0.7520\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5150 - accuracy: 0.7451 - val_loss: 0.5702 - val_accuracy: 0.7283\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5145 - accuracy: 0.7549 - val_loss: 0.5628 - val_accuracy: 0.7441\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s 184us/step - loss: 0.4978 - accuracy: 0.7529 - val_loss: 0.5610 - val_accuracy: 0.7087\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.5232 - accuracy: 0.7276 - val_loss: 0.5585 - val_accuracy: 0.7441\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.4992 - accuracy: 0.7412 - val_loss: 0.5716 - val_accuracy: 0.7126\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.5015 - accuracy: 0.7471 - val_loss: 0.5813 - val_accuracy: 0.7323\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s 184us/step - loss: 0.5052 - accuracy: 0.7529 - val_loss: 0.6333 - val_accuracy: 0.6929\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5122 - accuracy: 0.7568 - val_loss: 0.5691 - val_accuracy: 0.7165\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5149 - accuracy: 0.7315 - val_loss: 0.5739 - val_accuracy: 0.7520\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s 177us/step - loss: 0.5504 - accuracy: 0.7510 - val_loss: 0.5537 - val_accuracy: 0.7441\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.5247 - accuracy: 0.7315 - val_loss: 0.5536 - val_accuracy: 0.7441\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.5101 - accuracy: 0.7315 - val_loss: 0.6719 - val_accuracy: 0.6732\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.5134 - accuracy: 0.7374 - val_loss: 0.5524 - val_accuracy: 0.7520\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.5233 - accuracy: 0.7451 - val_loss: 0.5560 - val_accuracy: 0.7126\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5024 - accuracy: 0.7335 - val_loss: 0.6359 - val_accuracy: 0.6772\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.5366 - accuracy: 0.7374 - val_loss: 0.5993 - val_accuracy: 0.7283\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s 184us/step - loss: 0.5087 - accuracy: 0.7451 - val_loss: 0.5681 - val_accuracy: 0.7126\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.4977 - accuracy: 0.7451 - val_loss: 0.5526 - val_accuracy: 0.7323\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5029 - accuracy: 0.7607 - val_loss: 0.5644 - val_accuracy: 0.7638\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s 190us/step - loss: 0.4952 - accuracy: 0.7471 - val_loss: 0.5571 - val_accuracy: 0.7165\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s 190us/step - loss: 0.4879 - accuracy: 0.7451 - val_loss: 0.5727 - val_accuracy: 0.7520\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.4997 - accuracy: 0.7549 - val_loss: 0.6042 - val_accuracy: 0.7087\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s 194us/step - loss: 0.5167 - accuracy: 0.7490 - val_loss: 0.5605 - val_accuracy: 0.7205\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5119 - accuracy: 0.7510 - val_loss: 0.5646 - val_accuracy: 0.7165\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.4871 - accuracy: 0.7432 - val_loss: 0.5494 - val_accuracy: 0.7441\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.4970 - accuracy: 0.7412 - val_loss: 0.5546 - val_accuracy: 0.7205\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s 198us/step - loss: 0.4959 - accuracy: 0.7549 - val_loss: 0.5968 - val_accuracy: 0.7244\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.5010 - accuracy: 0.7490 - val_loss: 0.5526 - val_accuracy: 0.7441\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.4924 - accuracy: 0.7510 - val_loss: 0.5599 - val_accuracy: 0.7165\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.4960 - accuracy: 0.7646 - val_loss: 0.5722 - val_accuracy: 0.6850\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s 193us/step - loss: 0.5044 - accuracy: 0.7490 - val_loss: 0.5507 - val_accuracy: 0.7559\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.4883 - accuracy: 0.7665 - val_loss: 0.5595 - val_accuracy: 0.7795\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.5128 - accuracy: 0.7490 - val_loss: 0.5874 - val_accuracy: 0.7126\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s 180us/step - loss: 0.4989 - accuracy: 0.7568 - val_loss: 0.5507 - val_accuracy: 0.7402\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s 184us/step - loss: 0.4994 - accuracy: 0.7549 - val_loss: 0.5561 - val_accuracy: 0.7874\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.4909 - accuracy: 0.7685 - val_loss: 0.5833 - val_accuracy: 0.7087\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.4886 - accuracy: 0.7510 - val_loss: 0.5652 - val_accuracy: 0.7480\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.4949 - accuracy: 0.7568 - val_loss: 0.5594 - val_accuracy: 0.7441\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.4905 - accuracy: 0.7588 - val_loss: 0.5582 - val_accuracy: 0.7402\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.4900 - accuracy: 0.7549 - val_loss: 0.5913 - val_accuracy: 0.7441\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.5098 - accuracy: 0.7471 - val_loss: 0.5776 - val_accuracy: 0.7323\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.4841 - accuracy: 0.7471 - val_loss: 0.5701 - val_accuracy: 0.6929\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.4887 - accuracy: 0.7549 - val_loss: 0.6252 - val_accuracy: 0.6890\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.4974 - accuracy: 0.7471 - val_loss: 0.6386 - val_accuracy: 0.6850\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s 172us/step - loss: 0.5088 - accuracy: 0.7743 - val_loss: 0.5701 - val_accuracy: 0.7717\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.4982 - accuracy: 0.7588 - val_loss: 0.6020 - val_accuracy: 0.7126\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4954 - accuracy: 0.7607 - val_loss: 0.5865 - val_accuracy: 0.7441\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s 177us/step - loss: 0.4928 - accuracy: 0.7471 - val_loss: 0.5712 - val_accuracy: 0.7638\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.4874 - accuracy: 0.7588 - val_loss: 0.5499 - val_accuracy: 0.7402\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.5068 - accuracy: 0.7510 - val_loss: 0.5992 - val_accuracy: 0.6929\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.4967 - accuracy: 0.7432 - val_loss: 0.5957 - val_accuracy: 0.7165\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s 184us/step - loss: 0.4874 - accuracy: 0.7549 - val_loss: 0.5555 - val_accuracy: 0.7598\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4839 - accuracy: 0.7568 - val_loss: 0.5555 - val_accuracy: 0.7402\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.4842 - accuracy: 0.7588 - val_loss: 0.5556 - val_accuracy: 0.7835\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s 194us/step - loss: 0.4898 - accuracy: 0.7412 - val_loss: 0.5575 - val_accuracy: 0.7402\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.4716 - accuracy: 0.7529 - val_loss: 0.5500 - val_accuracy: 0.7283\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s 184us/step - loss: 0.4853 - accuracy: 0.7685 - val_loss: 0.5494 - val_accuracy: 0.7756\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.4929 - accuracy: 0.7685 - val_loss: 0.5846 - val_accuracy: 0.7402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f996c1520f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 8), (768,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "def train_model(model):\n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=10, random_state=7, shuffle=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.52%\n",
      "accuracy: 79.22%\n",
      "accuracy: 72.73%\n",
      "accuracy: 66.23%\n",
      "accuracy: 70.13%\n",
      "accuracy: 70.13%\n",
      "accuracy: 76.62%\n",
      "accuracy: 74.03%\n",
      "accuracy: 71.05%\n",
      "accuracy: 73.68%\n",
      "73.43% (+/- 4.17%)\n"
     ]
    }
   ],
   "source": [
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # Create\n",
    "    model = create_model()\n",
    "    \n",
    "    # Train\n",
    "    train_model(model)\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#72.53% (+/- 3.46%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import time\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    # load your data using this function  \n",
    "    \n",
    "    #(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # normalize\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    return x_train, y_train\n",
    "    \n",
    "    \n",
    "def create_model():\n",
    "    \n",
    "    # create your model using this function\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=input_shape))\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, x_train_cv, y_train_cv, x_val_cv, y_val_cv):\n",
    "    \n",
    "    # fit and evaluate here.\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train_cv = keras.utils.to_categorical(y_train_cv, num_classes)\n",
    "    y_val_cv = keras.utils.to_categorical(y_val_cv, num_classes)\n",
    "    \n",
    "    model.fit(x_train_cv,y_train_cv,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val_cv, y_val_cv))\n",
    "    \n",
    "    score = model.evaluate(x_val_cv, y_val_cv, verbose=0)\n",
    "    loss, acc = score[0], score[1]\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "#if not os.path.isdir(save_dir):\n",
    "#    os.makedirs(save_dir)\n",
    "#model_path = os.path.join(save_dir, model_name)\n",
    "#model.save(model_path)\n",
    "#print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "#scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "#print('Test loss:', scores[0])\n",
    "#print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "data, labels = load_data()\n",
    "print(data.shape, labels.shape)\n",
    "\n",
    "# define 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "print(kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  5  6  7  8  9 10 11 12] [ 0  1  2 14 17 21 24 25 33 41]\n",
      "Fold - 0 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "[ 0  1  2  3  4  5  6  7  9 12] [ 8 10 11 27 31 36 44 47 51 53]\n",
      "Fold - 1 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "[ 0  1  2  3  4  5  7  8  9 10] [ 6 28 29 35 38 43 45 46 49 54]\n",
      "Fold - 2 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "[ 0  1  2  6  7  8 10 11 12 14] [ 3  4  5  9 13 15 19 20 30 39]\n",
      "Fold - 3 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "[ 0  1  2  3  4  5  6  8  9 10] [ 7 12 16 18 22 23 26 32 34 37]\n",
      "Fold - 4 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "for i, (train, test) in enumerate(kfold.split(data, labels)):\n",
    "    print(train[:10], test[:10])\n",
    "    print(\"Fold - {}\".format(i), data[train].shape, labels[train].shape, data[test].shape, labels[test].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26274, 12256, 2818, 3008, 1217, 11330, 4287, 19905, 1284, 45482]\n",
      "40000\n",
      "40000\n",
      "[26274, 12256, 2818, 3008, 1217, 11330, 4287, 19905, 1284, 45482]\n",
      "10000\n",
      "[37040, 7378, 37157, 47567, 3004, 49861, 8045, 29036, 44466, 24734]\n"
     ]
    }
   ],
   "source": [
    "indices=list(range(len(data)))\n",
    "#np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "print(indices[:10])\n",
    "\n",
    "\n",
    "ind=int(len(indices)*0.80)\n",
    "print(ind)\n",
    "\n",
    "\n",
    "\n",
    "train_index = indices[:ind]\n",
    "print(len(train_index))\n",
    "print(train_index[:10])\n",
    "\n",
    "test = indices[-(len(indices)-ind):]\n",
    "print(len(test))\n",
    "print(test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 0 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Fold - 1 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Fold - 2 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Fold - 3 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Fold - 4 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Manual cross validation!!!!!!!!!!\n",
    "\n",
    "for i in range(5):\n",
    "    indices=list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    ind=int(len(indices)*0.80)\n",
    "    train = indices[:ind]\n",
    "    test = indices[-(len(indices)-ind):]\n",
    "    print(\"Fold - {}\".format(i), data[train].shape, labels[train].shape, data[test].shape, labels[test].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 0 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 1.8891 - accuracy: 0.3082 - val_loss: 1.5883 - val_accuracy: 0.4273\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 8s 195us/step - loss: 1.5552 - accuracy: 0.4321 - val_loss: 1.4067 - val_accuracy: 0.4971\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 1.4240 - accuracy: 0.4880 - val_loss: 1.2968 - val_accuracy: 0.5351\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 1.3311 - accuracy: 0.5222 - val_loss: 1.2311 - val_accuracy: 0.5657\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 7s 186us/step - loss: 1.2504 - accuracy: 0.5570 - val_loss: 1.1721 - val_accuracy: 0.5863\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.1818 - accuracy: 0.5791 - val_loss: 1.0790 - val_accuracy: 0.6183\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 1.1235 - accuracy: 0.6007 - val_loss: 1.0294 - val_accuracy: 0.6363\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 8s 211us/step - loss: 1.0735 - accuracy: 0.6229 - val_loss: 0.9718 - val_accuracy: 0.6562\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 1.0271 - accuracy: 0.6373 - val_loss: 0.9553 - val_accuracy: 0.6638\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.9857 - accuracy: 0.6535 - val_loss: 0.9606 - val_accuracy: 0.6569\n",
      "--- Time taken to train : 0.0 hours ---\n",
      "Fold - 1 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.8577 - accuracy: 0.3187 - val_loss: 1.5676 - val_accuracy: 0.4363\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.5380 - accuracy: 0.4427 - val_loss: 1.3934 - val_accuracy: 0.5026\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 1.3990 - accuracy: 0.5005 - val_loss: 1.2988 - val_accuracy: 0.5379\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 1.3071 - accuracy: 0.5353 - val_loss: 1.2013 - val_accuracy: 0.5756\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 1.2287 - accuracy: 0.5637 - val_loss: 1.1371 - val_accuracy: 0.5974\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 1.1635 - accuracy: 0.5900 - val_loss: 1.0788 - val_accuracy: 0.6180\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 8s 208us/step - loss: 1.1067 - accuracy: 0.6094 - val_loss: 1.0247 - val_accuracy: 0.6356\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.0561 - accuracy: 0.6327 - val_loss: 0.9778 - val_accuracy: 0.6522\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.0182 - accuracy: 0.6440 - val_loss: 0.9484 - val_accuracy: 0.6638\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 8s 189us/step - loss: 0.9733 - accuracy: 0.6610 - val_loss: 0.9094 - val_accuracy: 0.6782\n",
      "--- Time taken to train : 0.0 hours ---\n",
      "Fold - 2 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.8478 - accuracy: 0.3203 - val_loss: 1.5977 - val_accuracy: 0.4247\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 8s 209us/step - loss: 1.5525 - accuracy: 0.4320 - val_loss: 1.4193 - val_accuracy: 0.4903\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 7s 184us/step - loss: 1.4183 - accuracy: 0.4884 - val_loss: 1.3353 - val_accuracy: 0.5209\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.3195 - accuracy: 0.5278 - val_loss: 1.2284 - val_accuracy: 0.5624\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 1.2414 - accuracy: 0.5582 - val_loss: 1.1658 - val_accuracy: 0.5872\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.1776 - accuracy: 0.5831 - val_loss: 1.1337 - val_accuracy: 0.6091\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.1195 - accuracy: 0.6036 - val_loss: 1.0544 - val_accuracy: 0.6313\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 1.0728 - accuracy: 0.6218 - val_loss: 1.0353 - val_accuracy: 0.6412\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 1.0304 - accuracy: 0.6373 - val_loss: 0.9977 - val_accuracy: 0.6581\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 0.9962 - accuracy: 0.6486 - val_loss: 0.9520 - val_accuracy: 0.6704\n",
      "--- Time taken to train : 0.0 hours ---\n",
      "Fold - 3 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.8475 - accuracy: 0.3192 - val_loss: 1.6369 - val_accuracy: 0.4080\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 7s 180us/step - loss: 1.5680 - accuracy: 0.4270 - val_loss: 1.4261 - val_accuracy: 0.4859\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 1.4245 - accuracy: 0.4864 - val_loss: 1.2993 - val_accuracy: 0.5328\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 1.3197 - accuracy: 0.5295 - val_loss: 1.2205 - val_accuracy: 0.5677\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 8s 202us/step - loss: 1.2410 - accuracy: 0.5601 - val_loss: 1.1545 - val_accuracy: 0.5916\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 1.1719 - accuracy: 0.5862 - val_loss: 1.0901 - val_accuracy: 0.6063\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 8s 212us/step - loss: 1.1131 - accuracy: 0.6086 - val_loss: 1.0277 - val_accuracy: 0.6281\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 1.0656 - accuracy: 0.6262 - val_loss: 1.0293 - val_accuracy: 0.6310\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.0245 - accuracy: 0.6417 - val_loss: 0.9447 - val_accuracy: 0.6652\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 5s 136us/step - loss: 0.9884 - accuracy: 0.6519 - val_loss: 0.9350 - val_accuracy: 0.6690\n",
      "--- Time taken to train : 0.0 hours ---\n",
      "Fold - 4 (40000, 32, 32, 3) (40000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 8s 200us/step - loss: 1.8842 - accuracy: 0.3088 - val_loss: 1.5937 - val_accuracy: 0.4240\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 1.5511 - accuracy: 0.4358 - val_loss: 1.4035 - val_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 1.4096 - accuracy: 0.4929 - val_loss: 1.3448 - val_accuracy: 0.5192\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 5s 119us/step - loss: 1.3107 - accuracy: 0.5351 - val_loss: 1.2317 - val_accuracy: 0.5592\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 1.2313 - accuracy: 0.5658 - val_loss: 1.1610 - val_accuracy: 0.5823\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 1.1649 - accuracy: 0.5907 - val_loss: 1.0863 - val_accuracy: 0.6166\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.1088 - accuracy: 0.6116 - val_loss: 1.0219 - val_accuracy: 0.6367\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 8s 188us/step - loss: 1.0586 - accuracy: 0.6268 - val_loss: 0.9771 - val_accuracy: 0.6578\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 8s 192us/step - loss: 1.0170 - accuracy: 0.6456 - val_loss: 0.9616 - val_accuracy: 0.6622\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 7s 185us/step - loss: 0.9832 - accuracy: 0.6562 - val_loss: 0.9544 - val_accuracy: 0.6637\n",
      "--- Time taken to train : 0.0 hours ---\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = []\n",
    "\n",
    "for i, (train, test) in enumerate(kfold.split(data, labels)):\n",
    "    \n",
    "    print(\"Fold - {}\".format(i), data[train].shape, labels[train].shape, data[test].shape, labels[test].shape)\n",
    "    \n",
    "    model = None # Clearing the NN.\n",
    "    \n",
    "    # Calculate the starting time    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    acc = train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))\n",
    "    \n",
    "    cross_val_scores.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67% (+/- 0.01%)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cross_val_scores), np.std(cross_val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6676400065422058, 0.00709722075734607)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_scores), np.std(cross_val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# #############################################################################\n",
    "# Data IO and generation\n",
    "\n",
    "# Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X, y = X[y != 2], y[y != 2]\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# #############################################################################\n",
    "# Classification and ROC analysis\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "classifier = svm.SVC(kernel='linear', probability=True,\n",
    "                     random_state=random_state)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X[train], y[train])\n",
    "    viz = plot_roc_curve(classifier, X[test], y[test],\n",
    "                         name='ROC fold {}'.format(i),\n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic example\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
